{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2561d1d-efef-49ca-9861-c5fd8687c685",
   "metadata": {},
   "source": [
    "## Running FairNow's Synthetic Fairness Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862abd08-8104-4834-baee-868ba97f9927",
   "metadata": {},
   "source": [
    "#### FairNow's Synthetic Fairness Simulation is a way to evaluate a model for bias without using real data. The simulation works by taking synthetically generated candidate resumes, then creates variants of each resume that belong to a different demographic group. We can evaluate bias by looking at the difference in scores for resumes from each demographic group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3a066-05bf-45bd-84a8-63c248b4c107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import zipfile\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b5bd9f-c671-4fc4-b5e4-2845ac8d668b",
   "metadata": {},
   "source": [
    "### Prerequisites:\n",
    "\n",
    "#### To use this notebook, you'll need a `client_id` and `client_secret`. These will either have been provided to you, or you can generate from https://app.fairnow.ai and going the the Admin menu. This notebook assumes you have these stored as environment variables:\n",
    "\n",
    "* FAIRNOW_CLIENT_ID\n",
    "* FAIRNOW_CLIENT_SECRET\n",
    "\n",
    "#### To run this you will need a `model_id` and `version` for the specific model you want to test. Details of how to create and lookup models can be found here: https://github.com/FairNow/API-Guides/blob/main/notebooks/Models%20API.ipynb\n",
    "\n",
    "#### Finally, you'll need a `bucket` value for generating the synthetic data, which will be provided to you or configurable within the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5bd176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the client secret and Id needed for OAuth2.0:\n",
    "client_id = os.getenv(\"FAIRNOW_CLIENT_ID\")\n",
    "client_secret = os.getenv(\"FAIRNOW_CLIENT_SECRET\")\n",
    "\n",
    "model_id = \"{model_id}\" # Replace with the correct modelId\n",
    "version = \"{version}\" # Replace with the correct version\n",
    "\n",
    "bucket = \"{bucket}\" # Replace with the correct bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5d1583",
   "metadata": {},
   "source": [
    "#### First, let's get an access token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03454b57-22f6-4bee-b46e-0148f47bf1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = None\n",
    "\n",
    "# Call the Auth endpoint to request a token:\n",
    "fairnow_token_endpoint = \"https://auth.fairnow.ai/oauth2/token\"\n",
    "scope = \"https://auth.fairnow.ai/FULL_ACCESS\"\n",
    "\n",
    "token_request_data = {\n",
    "    'grant_type': 'client_credentials',\n",
    "    'client_id': client_id,\n",
    "    'client_secret': client_secret,\n",
    "    'scope': scope\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(fairnow_token_endpoint, data=token_request_data)\n",
    "    if response.status_code == 200:\n",
    "        access_token = response.json().get('access_token')\n",
    "        print('Successfully created token')\n",
    "    else:\n",
    "        print(f'Error: {response.status_code} - {response.text}')\n",
    "        print(response)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'Request failed: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702a5c6d",
   "metadata": {},
   "source": [
    "#### Set up headers and endpoints that we will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167555c-bb18-47f6-90d6-96907bfc96da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers = {\"Authorization\": f\"Bearer {access_token}\", \"Accept\": \"application/json\"}\n",
    "\n",
    "fairnow_api = \"https://api.fairnow.ai/v1\"\n",
    "url = f\"{fairnow_api}/syntheticData\"\n",
    "post_scores_url = f\"{fairnow_api}/syntheticData/scores\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9928a4-f9ce-40ec-8774-d592dc496ebd",
   "metadata": {},
   "source": [
    "#### To start the process, hit POST:/v1/syntheticData. This returns the taskId used to track this job. In the background, synthetic data is being generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a981f66e-8f09-418d-9b3a-22712f06463a",
   "metadata": {},
   "source": [
    "#### The API has six arguments:\n",
    "  - `dataType` refers to the type of analysis job, which will be 'resume' in your case. \n",
    "  - `subType` refers to the specific bucket you want to test]. Valid values for subType vary by customer can be found in the app. \n",
    "  - `n_resumes_per_template` refers to the number of resumes to create from each template. This value must be passed as a string\n",
    "  - `modelId` and `version` refer to your model. Theses can be accessed through the GET models API in the Models API notebook in this repo\n",
    "  - `threshold` refers to the model score used to determine pass/fail.",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171a6243-fea5-4128-aecd-600f60f20b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"dataType\": \"resume\",\n",
    "    \"subType\": bucket,\n",
    "    \"nResumesPerTemplate\": \"5\",\n",
    "    \"modelId\": model_id,\n",
    "    \"version\": version \n",
    "    \"threshold\": 0.5 \n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "task_id = response.json()[\"taskId\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4885b2-4618-44bf-92d5-edfe80eb06c6",
   "metadata": {},
   "source": [
    "#### The synthetic data generation task runs in the background and can take a few minutes. Use the code below to query the API to know when the synthetic data is ready to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258fd80-39fa-4c41-885e-b566f87a3fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_task_url = f\"{fairnow_api}/syntheticData/tasks/{task_id}\"\n",
    "\n",
    "response = requests.get(get_task_url, headers=headers)\n",
    "current_status = response.json()['task']['status']\n",
    "\n",
    "while current_status == 'CREATING_DATA':\n",
    "    print('Polling task table to learn status every 15 seconds')\n",
    "    response = requests.get(get_task_url, headers=headers)\n",
    "    current_status = response.json()['task']['status']\n",
    "    print(f'Task status: `{current_status}`')\n",
    "    print()\n",
    "    sleep(15)\n",
    "\n",
    "download_scores_presigned_url = response.json()[\"task\"][\"presignedUrlSyntheticData\"]\n",
    "    \n",
    "print(f'Synthetic data has been created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f9c1b8-5e75-42fd-ae62-7aa968c452eb",
   "metadata": {},
   "source": [
    "#### Once the synthetic data is ready, the API will return a link for you to download the resumes as a zip file. The code below downloads and unzips the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bdaf88-bce6-474d-b603-9510d97ef63b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zip_file_path = 'temp_resumes.zip'\n",
    "extract_dir = 'temp_resumes'\n",
    "response = requests.get(download_scores_presigned_url)\n",
    "if response.status_code == 200:\n",
    "    with open(zip_file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"File extracted to {extract_dir}\")\n",
    "else:\n",
    "    print(\"Failed to download the file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4289ae52-b15a-4526-a854-074572316717",
   "metadata": {},
   "source": [
    "#### This is where you'll score each of the resumes and your model and collect the model scores. To do the analysis, you'll need to write each of the model scores to a csv file with the format {file_name},{model_score}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b6efc3-d059-4517-a138-cdf8fea31587",
   "metadata": {},
   "source": [
    "#### Here's an example of the csv format:\n",
    "\n",
    "```\n",
    "resume_template_1_Female_Asian_1.txt,0.4651875127622357\n",
    "resume_template_1_Female_Asian_2.txt,0.9039321758324333\n",
    "...\n",
    "resume_template_36_Male_White_5.txt,0.54982361689192743\n",
    "```\n",
    "\n",
    "**Note:** The csv file should have no header. It must contain a record for every file found in the downloaded zip file. And `model_score` must be a number value between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b40a6-1c65-44a4-b137-03c380bfe28e",
   "metadata": {},
   "source": [
    "#### Once the file is ready, hit the API below to receive a link that you'll use to upload the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f494921c-fd5f-464d-81e9-2f3062c92e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "post_scores_url = f\"{fairnow_api}/syntheticData/scores/{task_id}\"\n",
    "\n",
    "response = requests.post(post_scores_url, headers=headers)\n",
    "\n",
    "presigned_url = response.json()[\"task\"][\"uploadURL\"]\n",
    "key = response.json()[\"task\"][\"key\"]\n",
    "fields = response.json()[\"task\"][\"fields\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9569de-bb60-4bbc-8a60-85b580dffcd9",
   "metadata": {},
   "source": [
    "#### Use the link to upload scores. Once the scores are uploaded, this triggers the analysis job. This runs in the background again and can take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401fb138-4e33-48b7-8150-950dc571c07c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_path = 'scores.csv'\n",
    "files = {'file': (key, open(scores_path, 'r'))}\n",
    "\n",
    "response = requests.post(presigned_url, data=fields, files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241fb22c-bc1e-453f-bc6f-a213c9eb0ee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd8d89f-48cf-436d-b890-641dd4aa8390",
   "metadata": {},
   "source": [
    "#### We'll query the API again to know when the analysis has been finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bdc698-dfcc-4908-81b4-4ba4e41e750a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_task_url = f\"{fairnow_api}/syntheticData/tasks/{task_id}\"\n",
    "\n",
    "response = requests.get(get_task_url, headers=headers)\n",
    "current_status = response.json()['task']['status']\n",
    "\n",
    "while current_status != 'READY':\n",
    "    print('Polling task table to learn status every 15 seconds')\n",
    "    response = requests.get(get_task_url, headers=headers)\n",
    "    current_status = response.json()['task']['status']\n",
    "    print(f'Task status: `{current_status}`')\n",
    "    print()\n",
    "    sleep(15)\n",
    "\n",
    "print(f'Analysis results ready to download.')\n",
    "\n",
    "analysis_download_presigned_url = response.json()[\"task\"][\"presignedUrlAnalysisResults\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb4b2e-ee09-4ff2-a181-98b1ec9bb9f3",
   "metadata": {},
   "source": [
    "#### Once the analysis task is ready, it returns a presigned link you can use to download the analysis results. The output is a csv with the average model score by race and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed62297a-9fc9-449b-b0c0-5dce9aeb8d15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(analysis_download_presigned_url)\n",
    "\n",
    "with open('results.csv', 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2e5e8-ad6e-4067-99a9-0be943de4d40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat results.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

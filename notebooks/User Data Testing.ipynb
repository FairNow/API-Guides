{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9385e75a",
   "metadata": {},
   "source": [
    "## Running FairNow's User Data Bias Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918dd26",
   "metadata": {},
   "source": [
    "#### FairNow's User Data Testing is a way to evaluate a model for bias using real data. Please do not send any PII data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91867055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e0a4dc",
   "metadata": {},
   "source": [
    "### Prerequisites:\n",
    "\n",
    "#### To use this notebook, you'll need a `client_id` and `client_secret`. These will either have been provided to you, or you can generate from https://app.fairnow.ai and going the the Admin menu. This notebook assumes you have these stored as environment variables:\n",
    "\n",
    "* FAIRNOW_CLIENT_ID\n",
    "* FAIRNOW_CLIENT_SECRET\n",
    "\n",
    "#### To run this you will need a `model_id` and `version` for the specific model you want to test. Details of how to create and lookup models can be found here: https://github.com/FairNow/API-Guides/blob/main/notebooks/Models%20API.ipynb\n",
    "\n",
    "#### Finally, you'll need a `threshold` value, which is the value at which anyone with a score above is considered a passing score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32cb761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the client secret and Id needed for OAuth2.0:\n",
    "client_id = os.getenv(\"FAIRNOW_CLIENT_ID\")\n",
    "client_secret = os.getenv(\"FAIRNOW_CLIENT_SECRET\")\n",
    "\n",
    "model_id = \"{model_id}\" # Replace with the correct modelId\n",
    "version = \"{version}\" # Replace with the correct version\n",
    "\n",
    "threshold = {threshold value} # Replace with threshold value, a number between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfdfbb0",
   "metadata": {},
   "source": [
    "#### You will also need to prepare a CSV file to upload containing data. The first row contains the column names.\n",
    "\n",
    "#### The following columns are required:\n",
    "* `Race`\n",
    "* `Gender`\n",
    "* `TimeStamp` (ISO8601 Timestamp, e.g `2023-12-14T16:26:05.898156Z`)\n",
    "* `Score` (a number between 0 and 1)\n",
    "\n",
    "#### Additional columns can be added to allow filtering of data, e.g. `Job Title`, `Location` etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2acf45",
   "metadata": {},
   "source": [
    "#### First, let's get an access token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = None\n",
    "\n",
    "# Call the Auth endpoint to request a token:\n",
    "fairnow_token_endpoint = \"https://auth.fairnow.ai/oauth2/token\"\n",
    "scope = \"https://auth.fairnow.ai/FULL_ACCESS\"\n",
    "\n",
    "token_request_data = {\n",
    "    'grant_type': 'client_credentials',\n",
    "    'client_id': client_id,\n",
    "    'client_secret': client_secret,\n",
    "    'scope': scope\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(fairnow_token_endpoint, data=token_request_data)\n",
    "    if response.status_code == 200:\n",
    "        access_token = response.json().get('access_token')\n",
    "        print('Successfully created token')\n",
    "    else:\n",
    "        print(f'Error: {response.status_code} - {response.text}')\n",
    "        print(response)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'Request failed: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e268d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set up headers and endpoints that we will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Authorization\": f\"Bearer {access_token}\", \"Accept\": \"application/json\"}\n",
    "\n",
    "fairnow_api = \"https://api.fairnow.ai/v1\"\n",
    "url = f\"{fairnow_api}/userData/{model_id}/{version}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4394229",
   "metadata": {},
   "source": [
    "#### Next we create a task. We need to specify the model and version, and pass the threshold value. The response will include the `taskId` and the presigned URL to upload the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfffef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"threshold\": threshold\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "task_id = response.json()[\"task\"][\"taskId\"]\n",
    "presigned_url = response.json()[\"task\"][\"uploadURL\"]\n",
    "key = response.json()[\"task\"][\"key\"]\n",
    "fields = response.json()[\"task\"][\"fields\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ae39c",
   "metadata": {},
   "source": [
    "#### Use the link to upload scores. Once the scores are uploaded, this triggers the analysis job. This runs in the background again and can take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1282de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_path = 'scores.csv'\n",
    "files = {'file': (key, open(scores_path, 'r'))}\n",
    "\n",
    "response = requests.post(presigned_url, data=fields, files=files)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f42cfc8",
   "metadata": {},
   "source": [
    "#### We'll query the API again to know when the analysis has been finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dee0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_task_url = f\"{fairnow_api}/userData/tasks/{task_id}\"\n",
    "\n",
    "response = requests.get(get_task_url, headers=headers)\n",
    "current_status = response.json()['task']['status']\n",
    "\n",
    "while current_status != 'READY':\n",
    "    print('Polling task table to learn status every 15 seconds')\n",
    "    response = requests.get(get_task_url, headers=headers)\n",
    "    current_status = response.json()['task']['status']\n",
    "    print(f'Task status: `{current_status}`')\n",
    "    print()\n",
    "    sleep(15)\n",
    "\n",
    "print(f'Analysis results ready to download.')\n",
    "\n",
    "analysis_download_presigned_url = response.json()[\"task\"][\"presignedUrlAnalysisResults\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74efa5a",
   "metadata": {},
   "source": [
    "#### Once the analysis task is ready, it returns a presigned link you can use to download the analysis results. The output is a csv with the results by race and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(analysis_download_presigned_url)\n",
    "\n",
    "with open('results.csv', 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7378c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat results.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
